{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, we will examine lightning strike data collected by the National Oceanic and Atmospheric Association (NOAA) for the year of 2018. To complete this notebook, we will:\n",
    "\n",
    "* Find the locations with the greatest number of strikes within a single day\n",
    "* Examine the locations that had the greatest number of days with at least one lightning strike \n",
    "* Determine whether certain days of the week had more lightning strikes than others  \n",
    "* Add data from 2016 and 2017 and, for each month, calculate the percentage of total lightning strikes for that year that occurred in that month\n",
    "* Plot this data on a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>number_of_strikes</th>\n",
       "      <th>center_point_geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>194</td>\n",
       "      <td>POINT(-75 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>41</td>\n",
       "      <td>POINT(-78.4 29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>33</td>\n",
       "      <td>POINT(-73.9 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>38</td>\n",
       "      <td>POINT(-73.8 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>92</td>\n",
       "      <td>POINT(-79 28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  number_of_strikes center_point_geom\n",
       "0  2018-01-03                194     POINT(-75 27)\n",
       "1  2018-01-03                 41   POINT(-78.4 29)\n",
       "2  2018-01-03                 33   POINT(-73.9 27)\n",
       "3  2018-01-03                 38   POINT(-73.8 27)\n",
       "4  2018-01-03                 92     POINT(-79 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the 2018 data.\n",
    "df = pd.read_csv('eda_structuring_with_python_dataset1.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the `date` column to datetime.\n",
    "df['date'] = pd.to_datetime(df['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by number of strikes in descending order.\n",
    "df.sort_values(by='number_of_strikes', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the locations that appear most in the dataset.\n",
    "df.center_point_geom.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top 20 locations with most days of lightning.\n",
    "df.center_point_geom.value_counts()[:20].rename_axis('unique_values').reset_index(name='counts').style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns.\n",
    "df['week'] = df.date.dt.isocalendar().week\n",
    "df['weekday'] = df.date.dt.day_name()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean count of lightning strikes for each weekday.\n",
    "df[['weekday','number_of_strikes']].groupby(['weekday']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define order of days for the plot.\n",
    "weekday_order = ['Monday','Tuesday', 'Wednesday', 'Thursday','Friday','Saturday','Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots of strike counts for each day of week.\n",
    "g = sns.boxplot(data=df, \n",
    "            x='weekday',\n",
    "            y='number_of_strikes', \n",
    "            order=weekday_order, \n",
    "            showfliers=False \n",
    "            );\n",
    "g.set_title('Lightning distribution per weekday (2018)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2016–2017 data\n",
    "df_2 = pd.read_csv('eda_structuring_with_python_dataset2.csv')\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `date` column to datetime.\n",
    "df_2['date'] = pd.to_datetime(df_2['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe combining 2016–2017 data with 2018 data.\n",
    "union_df = pd.concat([df.drop(['weekday','week'],axis=1), df_2], ignore_index=True)\n",
    "union_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 3 new columns.\n",
    "union_df['year'] = union_df.date.dt.year\n",
    "union_df['month'] = union_df.date.dt.month\n",
    "union_df['month_txt'] = union_df.date.dt.month_name()\n",
    "union_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of strikes per year\n",
    "union_df[['year','number_of_strikes']].groupby(['year']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total lightning strikes for each month of each year.\n",
    "lightning_by_month = union_df.groupby(['month_txt','year']).agg(\n",
    "    number_of_strikes = pd.NamedAgg(column='number_of_strikes',aggfunc=sum)\n",
    "    ).reset_index()\n",
    "\n",
    "lightning_by_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total lightning strikes for each year.\n",
    "lightning_by_year = union_df.groupby(['year']).agg(\n",
    "  year_strikes = pd.NamedAgg(column='number_of_strikes',aggfunc=sum)\n",
    ").reset_index()\n",
    "\n",
    "lightning_by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine `lightning_by_month` and `lightning_by_year` dataframes into single dataframe.\n",
    "percentage_lightning = lightning_by_month.merge(lightning_by_year,on='year')\n",
    "percentage_lightning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new `percentage_lightning_per_month` column.\n",
    "percentage_lightning['percentage_lightning_per_month'] = (percentage_lightning.number_of_strikes/\n",
    "                                                          percentage_lightning.year_strikes * 100.0)\n",
    "percentage_lightning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6));\n",
    "\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "sns.barplot(\n",
    "    data = percentage_lightning,\n",
    "    x = 'month_txt',\n",
    "    y = 'percentage_lightning_per_month',\n",
    "    hue = 'year',\n",
    "    order = month_order );\n",
    "plt.xlabel(\"Month\");\n",
    "plt.ylabel(\"% of lightning strikes\");\n",
    "plt.title(\"% of lightning strikes each Month (2016-2018)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: adding new data set\n",
    "\n",
    "**Objective**\n",
    "\n",
    "We will be examining lightning strike data collected by the National Oceanic and Atmospheric Association (NOAA) for the month of August 2018. There are two datasets. The first includes five columns:  \n",
    "\n",
    "|date|center_point_geom|longitude|latitude|number_of_strikes|\n",
    "|---|---|---|---|---|\n",
    "\n",
    "The second dataset contains seven columns:\n",
    "\n",
    "|date|zip_code|city|state|state_code|center_point_geom|number_of_strikes|\n",
    "|---|---|---|---|---|---|---|  \n",
    "\n",
    "The first dataset has two unique colums: `longitude` and `latitude`.  \n",
    "The second dataset has four unique columns: `zip_code`, `city`, `state`, and `state_code`.  \n",
    "There are three columns that are common between them: `date`, `center_point_geom`, and `number_of_strikes`.\n",
    "\n",
    "We want to combine the two datasets into a single dataframe that has all of the information from both datasets. Ideally, both datasets will have the same number of entries for the same locations on the same dates. If they don't, we'll investigate which data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in second dataset\n",
    "df_zip = pd.read_csv('eda_missing_data_dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows of dataset 2\n",
    "df_zip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left-join the two datasets\n",
    "df_joined = df.merge(df_zip, how='left', on=['date','center_point_geom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows of the merged data\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics of the joined dataframe\n",
    "df_joined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df of just the rows that are missing data\n",
    "df_null_geo = df_joined[pd.isnull(df_joined.state_code)]\n",
    "df_null_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-null counts on merged dataframe\n",
    "df_joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows\n",
    "df_null_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df of just latitude, longitude, and number of strikes and group by latitude and longitude\n",
    "top_missing = df_null_geo[['latitude','longitude','number_of_strikes_x']\n",
    "            ].groupby(['latitude','longitude']\n",
    "                      ).sum().sort_values('number_of_strikes_x',ascending=False).reset_index()\n",
    "top_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px  # Be sure to import express\n",
    "# reduce size of db otherwise it could break\n",
    "fig = px.scatter_geo(top_missing[top_missing.number_of_strikes_x>=300],  # Input Pandas DataFrame\n",
    "                    lat=\"latitude\",  # DataFrame column with latitude\n",
    "                    lon=\"longitude\",  # DataFrame column with latitude\n",
    "                    size=\"number_of_strikes_x\") # Set to plot size as number of strikes\n",
    "fig.update_layout(\n",
    "    title_text = 'Missing data', # Create a Title\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
